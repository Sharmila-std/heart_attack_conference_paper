{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UK-k2hM1YzWQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "gs6vs1I6ZB_m",
        "outputId": "80c6f49e-a2e7-4338-856f-a2e26ede6f54"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Age  Gender Region  Blood_Pressure  Cholesterol   BMI  Heart_Rate  \\\n",
              "0   50    Male  Rural           110.0        196.5  15.9          76   \n",
              "1   40  Female  Urban           138.8        157.5  27.1          82   \n",
              "2   26    Male  Rural           116.0        210.1  27.2          71   \n",
              "3   54  Female  Rural           133.5        170.5  26.0          74   \n",
              "4   19  Female  Urban           108.0        224.5  27.5          67   \n",
              "\n",
              "  Exercise_Level  Smoking Alcohol_Consumption  ...  Heart_Attack  Angina  \\\n",
              "0           High    False            Moderate  ...         False   False   \n",
              "1       Moderate    False                 NaN  ...         False    True   \n",
              "2       Moderate    False            Moderate  ...         False   False   \n",
              "3       Moderate     True            Moderate  ...         False   False   \n",
              "4            Low    False                 NaN  ...         False   False   \n",
              "\n",
              "   Heart_Disease_History       Diet  Sleep_Hours  Medication Health_Awareness  \\\n",
              "0                  False  Unhealthy          9.4       False                5   \n",
              "1                  False  Unhealthy          5.5       False                1   \n",
              "2                  False  Unhealthy          8.8       False                4   \n",
              "3                  False    Healthy          8.2       False                2   \n",
              "4                  False  Unhealthy          5.9       False                4   \n",
              "\n",
              "   Daily_Water_Intake  Mental_Health  Obesity  \n",
              "0                 2.3              5    False  \n",
              "1                 5.0              4    False  \n",
              "2                 2.4              8    False  \n",
              "3                 2.7              6     True  \n",
              "4                 3.5              4     True  \n",
              "\n",
              "[5 rows x 23 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dc7c90d1-7f0d-494a-80d2-d48fdc95b550\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Region</th>\n",
              "      <th>Blood_Pressure</th>\n",
              "      <th>Cholesterol</th>\n",
              "      <th>BMI</th>\n",
              "      <th>Heart_Rate</th>\n",
              "      <th>Exercise_Level</th>\n",
              "      <th>Smoking</th>\n",
              "      <th>Alcohol_Consumption</th>\n",
              "      <th>...</th>\n",
              "      <th>Heart_Attack</th>\n",
              "      <th>Angina</th>\n",
              "      <th>Heart_Disease_History</th>\n",
              "      <th>Diet</th>\n",
              "      <th>Sleep_Hours</th>\n",
              "      <th>Medication</th>\n",
              "      <th>Health_Awareness</th>\n",
              "      <th>Daily_Water_Intake</th>\n",
              "      <th>Mental_Health</th>\n",
              "      <th>Obesity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>50</td>\n",
              "      <td>Male</td>\n",
              "      <td>Rural</td>\n",
              "      <td>110.0</td>\n",
              "      <td>196.5</td>\n",
              "      <td>15.9</td>\n",
              "      <td>76</td>\n",
              "      <td>High</td>\n",
              "      <td>False</td>\n",
              "      <td>Moderate</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>Unhealthy</td>\n",
              "      <td>9.4</td>\n",
              "      <td>False</td>\n",
              "      <td>5</td>\n",
              "      <td>2.3</td>\n",
              "      <td>5</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>40</td>\n",
              "      <td>Female</td>\n",
              "      <td>Urban</td>\n",
              "      <td>138.8</td>\n",
              "      <td>157.5</td>\n",
              "      <td>27.1</td>\n",
              "      <td>82</td>\n",
              "      <td>Moderate</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>Unhealthy</td>\n",
              "      <td>5.5</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>26</td>\n",
              "      <td>Male</td>\n",
              "      <td>Rural</td>\n",
              "      <td>116.0</td>\n",
              "      <td>210.1</td>\n",
              "      <td>27.2</td>\n",
              "      <td>71</td>\n",
              "      <td>Moderate</td>\n",
              "      <td>False</td>\n",
              "      <td>Moderate</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>Unhealthy</td>\n",
              "      <td>8.8</td>\n",
              "      <td>False</td>\n",
              "      <td>4</td>\n",
              "      <td>2.4</td>\n",
              "      <td>8</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>54</td>\n",
              "      <td>Female</td>\n",
              "      <td>Rural</td>\n",
              "      <td>133.5</td>\n",
              "      <td>170.5</td>\n",
              "      <td>26.0</td>\n",
              "      <td>74</td>\n",
              "      <td>Moderate</td>\n",
              "      <td>True</td>\n",
              "      <td>Moderate</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>Healthy</td>\n",
              "      <td>8.2</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "      <td>2.7</td>\n",
              "      <td>6</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>19</td>\n",
              "      <td>Female</td>\n",
              "      <td>Urban</td>\n",
              "      <td>108.0</td>\n",
              "      <td>224.5</td>\n",
              "      <td>27.5</td>\n",
              "      <td>67</td>\n",
              "      <td>Low</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>Unhealthy</td>\n",
              "      <td>5.9</td>\n",
              "      <td>False</td>\n",
              "      <td>4</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 23 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc7c90d1-7f0d-494a-80d2-d48fdc95b550')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dc7c90d1-7f0d-494a-80d2-d48fdc95b550 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dc7c90d1-7f0d-494a-80d2-d48fdc95b550');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-925d59fd-0cdf-4cc4-98c7-cdcfbc03453f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-925d59fd-0cdf-4cc4-98c7-cdcfbc03453f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-925d59fd-0cdf-4cc4-98c7-cdcfbc03453f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "#viewing the dataset from my github repository\n",
        "url=\"/content/heart_attack_russia_youth_vs_adult (1).csv\"\n",
        "df=pd.read_csv(url)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ie_WyH2rZNzF",
        "outputId": "1cfc7af7-2a0f-4efa-f181-133b88baa72b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial null value counts:\n",
            " Age                          0\n",
            "Gender                       0\n",
            "Region                       0\n",
            "Blood_Pressure               0\n",
            "Cholesterol                  0\n",
            "BMI                          0\n",
            "Heart_Rate                   0\n",
            "Exercise_Level               0\n",
            "Smoking                      0\n",
            "Alcohol_Consumption      25024\n",
            "Diabetes                     0\n",
            "Family_History               0\n",
            "Stress_Level                 0\n",
            "Heart_Attack                 0\n",
            "Angina                       0\n",
            "Heart_Disease_History        0\n",
            "Diet                         0\n",
            "Sleep_Hours                  0\n",
            "Medication                   0\n",
            "Health_Awareness             0\n",
            "Daily_Water_Intake           0\n",
            "Mental_Health                0\n",
            "Obesity                      0\n",
            "dtype: int64\n",
            "\n",
            "Final null value counts:\n",
            " Age                      0\n",
            "Gender                   0\n",
            "Region                   0\n",
            "Blood_Pressure           0\n",
            "Cholesterol              0\n",
            "BMI                      0\n",
            "Heart_Rate               0\n",
            "Exercise_Level           0\n",
            "Smoking                  0\n",
            "Alcohol_Consumption      0\n",
            "Diabetes                 0\n",
            "Family_History           0\n",
            "Stress_Level             0\n",
            "Heart_Attack             0\n",
            "Angina                   0\n",
            "Heart_Disease_History    0\n",
            "Diet                     0\n",
            "Sleep_Hours              0\n",
            "Medication               0\n",
            "Health_Awareness         0\n",
            "Daily_Water_Intake       0\n",
            "Mental_Health            0\n",
            "Obesity                  0\n",
            "dtype: int64\n",
            "\n",
            "Final DataFrame shape: (50000, 23)\n"
          ]
        }
      ],
      "source": [
        "df_new = df.copy()\n",
        "print(\"Initial null value counts:\\n\", df_new.isnull().sum())\n",
        "\n",
        "for col in df_new.select_dtypes(include=['float']).columns:\n",
        "    positive_values = df_new[col][df_new[col] > 0]\n",
        "    if not positive_values.empty:\n",
        "        mean_value = positive_values.mean()\n",
        "        df_new[col] = df_new[col].apply(lambda x: mean_value if x <= 0 or pd.isnull(x) else x)\n",
        "\n",
        "for column in df_new.select_dtypes(exclude='number').columns:\n",
        "    df_new[column] = df_new[column].astype(str)\n",
        "\n",
        "df_new = df_new.loc[:, ~df_new.columns.str.contains('^Unnamed')]\n",
        "df_new = df_new.dropna()\n",
        "\n",
        "print(\"\\nFinal null value counts:\\n\", df_new.isnull().sum())\n",
        "\n",
        "print(\"\\nFinal DataFrame shape:\", df_new.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        },
        "id": "ih0OMSpfZVyB",
        "outputId": "f7a36c61-8877-4fc2-a0c0-cc54feced711"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                            Age    Gender    Region  Blood_Pressure  \\\n",
              "Age                    1.000000  0.006217  0.000360       -0.000037   \n",
              "Gender                 0.006217  1.000000  0.003473       -0.001385   \n",
              "Region                 0.000360  0.003473  1.000000        0.000274   \n",
              "Blood_Pressure        -0.000037 -0.001385  0.000274        1.000000   \n",
              "Cholesterol           -0.005028  0.000670 -0.002419        0.001426   \n",
              "BMI                    0.002640 -0.001509  0.001892       -0.004789   \n",
              "Heart_Rate            -0.003697  0.005610 -0.002656       -0.012488   \n",
              "Exercise_Level         0.012338 -0.002092  0.009957        0.009455   \n",
              "Smoking               -0.001180 -0.000642 -0.001593       -0.002458   \n",
              "Alcohol_Consumption    0.001938  0.001581  0.002901       -0.008163   \n",
              "Diabetes               0.004984 -0.005570 -0.000747        0.004579   \n",
              "Family_History         0.002473 -0.002276 -0.002684       -0.002315   \n",
              "Stress_Level           0.009260  0.000041  0.000645       -0.000293   \n",
              "Heart_Attack           0.000841 -0.002019 -0.003745       -0.010560   \n",
              "Angina                 0.003647  0.000502  0.007911        0.009775   \n",
              "Heart_Disease_History  0.004696  0.000630 -0.005312        0.006524   \n",
              "Diet                   0.004960  0.002848 -0.000111        0.003050   \n",
              "Sleep_Hours           -0.009355 -0.006928 -0.003595       -0.001150   \n",
              "Medication            -0.004225 -0.010958  0.003607       -0.006725   \n",
              "Health_Awareness       0.006636 -0.004616  0.000250       -0.003992   \n",
              "Daily_Water_Intake     0.001802  0.004287 -0.000070       -0.001918   \n",
              "Mental_Health         -0.000388  0.002471  0.000600        0.003967   \n",
              "Obesity                0.004632  0.001732 -0.001415        0.006876   \n",
              "\n",
              "                       Cholesterol       BMI  Heart_Rate  Exercise_Level  \\\n",
              "Age                      -0.005028  0.002640   -0.003697        0.012338   \n",
              "Gender                    0.000670 -0.001509    0.005610       -0.002092   \n",
              "Region                   -0.002419  0.001892   -0.002656        0.009957   \n",
              "Blood_Pressure            0.001426 -0.004789   -0.012488        0.009455   \n",
              "Cholesterol               1.000000  0.007163    0.002043        0.004223   \n",
              "BMI                       0.007163  1.000000   -0.009491       -0.003799   \n",
              "Heart_Rate                0.002043 -0.009491    1.000000        0.004131   \n",
              "Exercise_Level            0.004223 -0.003799    0.004131        1.000000   \n",
              "Smoking                  -0.000226  0.005467   -0.011459       -0.005273   \n",
              "Alcohol_Consumption      -0.004555  0.005707    0.004087       -0.000960   \n",
              "Diabetes                  0.002103 -0.004836    0.000611        0.000905   \n",
              "Family_History           -0.005121 -0.002309   -0.003906       -0.005169   \n",
              "Stress_Level              0.003322  0.003273   -0.003364       -0.000174   \n",
              "Heart_Attack             -0.003460 -0.000526   -0.002241       -0.000108   \n",
              "Angina                   -0.000882  0.000228    0.003273        0.002229   \n",
              "Heart_Disease_History    -0.000067  0.001396    0.010129       -0.001870   \n",
              "Diet                      0.004305 -0.001738    0.002635        0.000345   \n",
              "Sleep_Hours              -0.008843  0.003105    0.007489        0.002983   \n",
              "Medication                0.006578 -0.007269   -0.008292        0.005603   \n",
              "Health_Awareness          0.001360 -0.003134   -0.001228       -0.002390   \n",
              "Daily_Water_Intake       -0.000098 -0.001232   -0.000040       -0.000949   \n",
              "Mental_Health             0.001024  0.000980   -0.001706       -0.001284   \n",
              "Obesity                   0.004433 -0.009421    0.004157        0.001542   \n",
              "\n",
              "                        Smoking  Alcohol_Consumption  ...  Heart_Attack  \\\n",
              "Age                   -0.001180             0.001938  ...      0.000841   \n",
              "Gender                -0.000642             0.001581  ...     -0.002019   \n",
              "Region                -0.001593             0.002901  ...     -0.003745   \n",
              "Blood_Pressure        -0.002458            -0.008163  ...     -0.010560   \n",
              "Cholesterol           -0.000226            -0.004555  ...     -0.003460   \n",
              "BMI                    0.005467             0.005707  ...     -0.000526   \n",
              "Heart_Rate            -0.011459             0.004087  ...     -0.002241   \n",
              "Exercise_Level        -0.005273            -0.000960  ...     -0.000108   \n",
              "Smoking                1.000000             0.000739  ...      0.010113   \n",
              "Alcohol_Consumption    0.000739             1.000000  ...     -0.002310   \n",
              "Diabetes               0.002883            -0.004423  ...     -0.004789   \n",
              "Family_History         0.008568            -0.009310  ...      0.000322   \n",
              "Stress_Level          -0.003033             0.002228  ...     -0.005845   \n",
              "Heart_Attack           0.010113            -0.002310  ...      1.000000   \n",
              "Angina                 0.006129            -0.001348  ...      0.002055   \n",
              "Heart_Disease_History  0.001747             0.002449  ...     -0.004472   \n",
              "Diet                  -0.005153             0.002364  ...     -0.002529   \n",
              "Sleep_Hours            0.002280            -0.004560  ...      0.003141   \n",
              "Medication             0.000927            -0.002703  ...     -0.006285   \n",
              "Health_Awareness       0.004412             0.001574  ...     -0.003775   \n",
              "Daily_Water_Intake    -0.004509            -0.006140  ...      0.001709   \n",
              "Mental_Health          0.003781            -0.000389  ...     -0.000619   \n",
              "Obesity               -0.001294             0.009861  ...     -0.000750   \n",
              "\n",
              "                         Angina  Heart_Disease_History      Diet  Sleep_Hours  \\\n",
              "Age                    0.003647               0.004696  0.004960    -0.009355   \n",
              "Gender                 0.000502               0.000630  0.002848    -0.006928   \n",
              "Region                 0.007911              -0.005312 -0.000111    -0.003595   \n",
              "Blood_Pressure         0.009775               0.006524  0.003050    -0.001150   \n",
              "Cholesterol           -0.000882              -0.000067  0.004305    -0.008843   \n",
              "BMI                    0.000228               0.001396 -0.001738     0.003105   \n",
              "Heart_Rate             0.003273               0.010129  0.002635     0.007489   \n",
              "Exercise_Level         0.002229              -0.001870  0.000345     0.002983   \n",
              "Smoking                0.006129               0.001747 -0.005153     0.002280   \n",
              "Alcohol_Consumption   -0.001348               0.002449  0.002364    -0.004560   \n",
              "Diabetes               0.000357               0.004384 -0.004146    -0.004416   \n",
              "Family_History         0.001452               0.000366  0.000390     0.007807   \n",
              "Stress_Level           0.002903               0.004305 -0.004041    -0.003462   \n",
              "Heart_Attack           0.002055              -0.004472 -0.002529     0.003141   \n",
              "Angina                 1.000000              -0.003399  0.010733    -0.001165   \n",
              "Heart_Disease_History -0.003399               1.000000 -0.001147     0.001604   \n",
              "Diet                   0.010733              -0.001147  1.000000    -0.000579   \n",
              "Sleep_Hours           -0.001165               0.001604 -0.000579     1.000000   \n",
              "Medication            -0.001482              -0.001613 -0.008846    -0.001683   \n",
              "Health_Awareness       0.000699              -0.006655  0.000972    -0.006784   \n",
              "Daily_Water_Intake    -0.007631              -0.005640  0.001579    -0.001963   \n",
              "Mental_Health          0.004531               0.004353 -0.003826    -0.001707   \n",
              "Obesity               -0.002611               0.005415 -0.000374    -0.000031   \n",
              "\n",
              "                       Medication  Health_Awareness  Daily_Water_Intake  \\\n",
              "Age                     -0.004225          0.006636            0.001802   \n",
              "Gender                  -0.010958         -0.004616            0.004287   \n",
              "Region                   0.003607          0.000250           -0.000070   \n",
              "Blood_Pressure          -0.006725         -0.003992           -0.001918   \n",
              "Cholesterol              0.006578          0.001360           -0.000098   \n",
              "BMI                     -0.007269         -0.003134           -0.001232   \n",
              "Heart_Rate              -0.008292         -0.001228           -0.000040   \n",
              "Exercise_Level           0.005603         -0.002390           -0.000949   \n",
              "Smoking                  0.000927          0.004412           -0.004509   \n",
              "Alcohol_Consumption     -0.002703          0.001574           -0.006140   \n",
              "Diabetes                 0.002102          0.003281           -0.003994   \n",
              "Family_History           0.002970         -0.003600           -0.007358   \n",
              "Stress_Level             0.001189          0.002120           -0.005964   \n",
              "Heart_Attack            -0.006285         -0.003775            0.001709   \n",
              "Angina                  -0.001482          0.000699           -0.007631   \n",
              "Heart_Disease_History   -0.001613         -0.006655           -0.005640   \n",
              "Diet                    -0.008846          0.000972            0.001579   \n",
              "Sleep_Hours             -0.001683         -0.006784           -0.001963   \n",
              "Medication               1.000000          0.007815            0.000954   \n",
              "Health_Awareness         0.007815          1.000000           -0.004641   \n",
              "Daily_Water_Intake       0.000954         -0.004641            1.000000   \n",
              "Mental_Health           -0.001177         -0.000371            0.001514   \n",
              "Obesity                  0.000193          0.007906           -0.000446   \n",
              "\n",
              "                       Mental_Health   Obesity  \n",
              "Age                        -0.000388  0.004632  \n",
              "Gender                      0.002471  0.001732  \n",
              "Region                      0.000600 -0.001415  \n",
              "Blood_Pressure              0.003967  0.006876  \n",
              "Cholesterol                 0.001024  0.004433  \n",
              "BMI                         0.000980 -0.009421  \n",
              "Heart_Rate                 -0.001706  0.004157  \n",
              "Exercise_Level             -0.001284  0.001542  \n",
              "Smoking                     0.003781 -0.001294  \n",
              "Alcohol_Consumption        -0.000389  0.009861  \n",
              "Diabetes                   -0.001064  0.001094  \n",
              "Family_History             -0.008587  0.001010  \n",
              "Stress_Level               -0.005335 -0.006094  \n",
              "Heart_Attack               -0.000619 -0.000750  \n",
              "Angina                      0.004531 -0.002611  \n",
              "Heart_Disease_History       0.004353  0.005415  \n",
              "Diet                       -0.003826 -0.000374  \n",
              "Sleep_Hours                -0.001707 -0.000031  \n",
              "Medication                 -0.001177  0.000193  \n",
              "Health_Awareness           -0.000371  0.007906  \n",
              "Daily_Water_Intake          0.001514 -0.000446  \n",
              "Mental_Health               1.000000 -0.000349  \n",
              "Obesity                    -0.000349  1.000000  \n",
              "\n",
              "[23 rows x 23 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5e623729-3a37-4478-b28e-eda17ddddb1f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Region</th>\n",
              "      <th>Blood_Pressure</th>\n",
              "      <th>Cholesterol</th>\n",
              "      <th>BMI</th>\n",
              "      <th>Heart_Rate</th>\n",
              "      <th>Exercise_Level</th>\n",
              "      <th>Smoking</th>\n",
              "      <th>Alcohol_Consumption</th>\n",
              "      <th>...</th>\n",
              "      <th>Heart_Attack</th>\n",
              "      <th>Angina</th>\n",
              "      <th>Heart_Disease_History</th>\n",
              "      <th>Diet</th>\n",
              "      <th>Sleep_Hours</th>\n",
              "      <th>Medication</th>\n",
              "      <th>Health_Awareness</th>\n",
              "      <th>Daily_Water_Intake</th>\n",
              "      <th>Mental_Health</th>\n",
              "      <th>Obesity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Age</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.006217</td>\n",
              "      <td>0.000360</td>\n",
              "      <td>-0.000037</td>\n",
              "      <td>-0.005028</td>\n",
              "      <td>0.002640</td>\n",
              "      <td>-0.003697</td>\n",
              "      <td>0.012338</td>\n",
              "      <td>-0.001180</td>\n",
              "      <td>0.001938</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000841</td>\n",
              "      <td>0.003647</td>\n",
              "      <td>0.004696</td>\n",
              "      <td>0.004960</td>\n",
              "      <td>-0.009355</td>\n",
              "      <td>-0.004225</td>\n",
              "      <td>0.006636</td>\n",
              "      <td>0.001802</td>\n",
              "      <td>-0.000388</td>\n",
              "      <td>0.004632</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Gender</th>\n",
              "      <td>0.006217</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.003473</td>\n",
              "      <td>-0.001385</td>\n",
              "      <td>0.000670</td>\n",
              "      <td>-0.001509</td>\n",
              "      <td>0.005610</td>\n",
              "      <td>-0.002092</td>\n",
              "      <td>-0.000642</td>\n",
              "      <td>0.001581</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.002019</td>\n",
              "      <td>0.000502</td>\n",
              "      <td>0.000630</td>\n",
              "      <td>0.002848</td>\n",
              "      <td>-0.006928</td>\n",
              "      <td>-0.010958</td>\n",
              "      <td>-0.004616</td>\n",
              "      <td>0.004287</td>\n",
              "      <td>0.002471</td>\n",
              "      <td>0.001732</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Region</th>\n",
              "      <td>0.000360</td>\n",
              "      <td>0.003473</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000274</td>\n",
              "      <td>-0.002419</td>\n",
              "      <td>0.001892</td>\n",
              "      <td>-0.002656</td>\n",
              "      <td>0.009957</td>\n",
              "      <td>-0.001593</td>\n",
              "      <td>0.002901</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.003745</td>\n",
              "      <td>0.007911</td>\n",
              "      <td>-0.005312</td>\n",
              "      <td>-0.000111</td>\n",
              "      <td>-0.003595</td>\n",
              "      <td>0.003607</td>\n",
              "      <td>0.000250</td>\n",
              "      <td>-0.000070</td>\n",
              "      <td>0.000600</td>\n",
              "      <td>-0.001415</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Blood_Pressure</th>\n",
              "      <td>-0.000037</td>\n",
              "      <td>-0.001385</td>\n",
              "      <td>0.000274</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.001426</td>\n",
              "      <td>-0.004789</td>\n",
              "      <td>-0.012488</td>\n",
              "      <td>0.009455</td>\n",
              "      <td>-0.002458</td>\n",
              "      <td>-0.008163</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.010560</td>\n",
              "      <td>0.009775</td>\n",
              "      <td>0.006524</td>\n",
              "      <td>0.003050</td>\n",
              "      <td>-0.001150</td>\n",
              "      <td>-0.006725</td>\n",
              "      <td>-0.003992</td>\n",
              "      <td>-0.001918</td>\n",
              "      <td>0.003967</td>\n",
              "      <td>0.006876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cholesterol</th>\n",
              "      <td>-0.005028</td>\n",
              "      <td>0.000670</td>\n",
              "      <td>-0.002419</td>\n",
              "      <td>0.001426</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.007163</td>\n",
              "      <td>0.002043</td>\n",
              "      <td>0.004223</td>\n",
              "      <td>-0.000226</td>\n",
              "      <td>-0.004555</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.003460</td>\n",
              "      <td>-0.000882</td>\n",
              "      <td>-0.000067</td>\n",
              "      <td>0.004305</td>\n",
              "      <td>-0.008843</td>\n",
              "      <td>0.006578</td>\n",
              "      <td>0.001360</td>\n",
              "      <td>-0.000098</td>\n",
              "      <td>0.001024</td>\n",
              "      <td>0.004433</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BMI</th>\n",
              "      <td>0.002640</td>\n",
              "      <td>-0.001509</td>\n",
              "      <td>0.001892</td>\n",
              "      <td>-0.004789</td>\n",
              "      <td>0.007163</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.009491</td>\n",
              "      <td>-0.003799</td>\n",
              "      <td>0.005467</td>\n",
              "      <td>0.005707</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.000526</td>\n",
              "      <td>0.000228</td>\n",
              "      <td>0.001396</td>\n",
              "      <td>-0.001738</td>\n",
              "      <td>0.003105</td>\n",
              "      <td>-0.007269</td>\n",
              "      <td>-0.003134</td>\n",
              "      <td>-0.001232</td>\n",
              "      <td>0.000980</td>\n",
              "      <td>-0.009421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Heart_Rate</th>\n",
              "      <td>-0.003697</td>\n",
              "      <td>0.005610</td>\n",
              "      <td>-0.002656</td>\n",
              "      <td>-0.012488</td>\n",
              "      <td>0.002043</td>\n",
              "      <td>-0.009491</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.004131</td>\n",
              "      <td>-0.011459</td>\n",
              "      <td>0.004087</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.002241</td>\n",
              "      <td>0.003273</td>\n",
              "      <td>0.010129</td>\n",
              "      <td>0.002635</td>\n",
              "      <td>0.007489</td>\n",
              "      <td>-0.008292</td>\n",
              "      <td>-0.001228</td>\n",
              "      <td>-0.000040</td>\n",
              "      <td>-0.001706</td>\n",
              "      <td>0.004157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Exercise_Level</th>\n",
              "      <td>0.012338</td>\n",
              "      <td>-0.002092</td>\n",
              "      <td>0.009957</td>\n",
              "      <td>0.009455</td>\n",
              "      <td>0.004223</td>\n",
              "      <td>-0.003799</td>\n",
              "      <td>0.004131</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.005273</td>\n",
              "      <td>-0.000960</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.000108</td>\n",
              "      <td>0.002229</td>\n",
              "      <td>-0.001870</td>\n",
              "      <td>0.000345</td>\n",
              "      <td>0.002983</td>\n",
              "      <td>0.005603</td>\n",
              "      <td>-0.002390</td>\n",
              "      <td>-0.000949</td>\n",
              "      <td>-0.001284</td>\n",
              "      <td>0.001542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Smoking</th>\n",
              "      <td>-0.001180</td>\n",
              "      <td>-0.000642</td>\n",
              "      <td>-0.001593</td>\n",
              "      <td>-0.002458</td>\n",
              "      <td>-0.000226</td>\n",
              "      <td>0.005467</td>\n",
              "      <td>-0.011459</td>\n",
              "      <td>-0.005273</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000739</td>\n",
              "      <td>...</td>\n",
              "      <td>0.010113</td>\n",
              "      <td>0.006129</td>\n",
              "      <td>0.001747</td>\n",
              "      <td>-0.005153</td>\n",
              "      <td>0.002280</td>\n",
              "      <td>0.000927</td>\n",
              "      <td>0.004412</td>\n",
              "      <td>-0.004509</td>\n",
              "      <td>0.003781</td>\n",
              "      <td>-0.001294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Alcohol_Consumption</th>\n",
              "      <td>0.001938</td>\n",
              "      <td>0.001581</td>\n",
              "      <td>0.002901</td>\n",
              "      <td>-0.008163</td>\n",
              "      <td>-0.004555</td>\n",
              "      <td>0.005707</td>\n",
              "      <td>0.004087</td>\n",
              "      <td>-0.000960</td>\n",
              "      <td>0.000739</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.002310</td>\n",
              "      <td>-0.001348</td>\n",
              "      <td>0.002449</td>\n",
              "      <td>0.002364</td>\n",
              "      <td>-0.004560</td>\n",
              "      <td>-0.002703</td>\n",
              "      <td>0.001574</td>\n",
              "      <td>-0.006140</td>\n",
              "      <td>-0.000389</td>\n",
              "      <td>0.009861</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Diabetes</th>\n",
              "      <td>0.004984</td>\n",
              "      <td>-0.005570</td>\n",
              "      <td>-0.000747</td>\n",
              "      <td>0.004579</td>\n",
              "      <td>0.002103</td>\n",
              "      <td>-0.004836</td>\n",
              "      <td>0.000611</td>\n",
              "      <td>0.000905</td>\n",
              "      <td>0.002883</td>\n",
              "      <td>-0.004423</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.004789</td>\n",
              "      <td>0.000357</td>\n",
              "      <td>0.004384</td>\n",
              "      <td>-0.004146</td>\n",
              "      <td>-0.004416</td>\n",
              "      <td>0.002102</td>\n",
              "      <td>0.003281</td>\n",
              "      <td>-0.003994</td>\n",
              "      <td>-0.001064</td>\n",
              "      <td>0.001094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Family_History</th>\n",
              "      <td>0.002473</td>\n",
              "      <td>-0.002276</td>\n",
              "      <td>-0.002684</td>\n",
              "      <td>-0.002315</td>\n",
              "      <td>-0.005121</td>\n",
              "      <td>-0.002309</td>\n",
              "      <td>-0.003906</td>\n",
              "      <td>-0.005169</td>\n",
              "      <td>0.008568</td>\n",
              "      <td>-0.009310</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000322</td>\n",
              "      <td>0.001452</td>\n",
              "      <td>0.000366</td>\n",
              "      <td>0.000390</td>\n",
              "      <td>0.007807</td>\n",
              "      <td>0.002970</td>\n",
              "      <td>-0.003600</td>\n",
              "      <td>-0.007358</td>\n",
              "      <td>-0.008587</td>\n",
              "      <td>0.001010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Stress_Level</th>\n",
              "      <td>0.009260</td>\n",
              "      <td>0.000041</td>\n",
              "      <td>0.000645</td>\n",
              "      <td>-0.000293</td>\n",
              "      <td>0.003322</td>\n",
              "      <td>0.003273</td>\n",
              "      <td>-0.003364</td>\n",
              "      <td>-0.000174</td>\n",
              "      <td>-0.003033</td>\n",
              "      <td>0.002228</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.005845</td>\n",
              "      <td>0.002903</td>\n",
              "      <td>0.004305</td>\n",
              "      <td>-0.004041</td>\n",
              "      <td>-0.003462</td>\n",
              "      <td>0.001189</td>\n",
              "      <td>0.002120</td>\n",
              "      <td>-0.005964</td>\n",
              "      <td>-0.005335</td>\n",
              "      <td>-0.006094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Heart_Attack</th>\n",
              "      <td>0.000841</td>\n",
              "      <td>-0.002019</td>\n",
              "      <td>-0.003745</td>\n",
              "      <td>-0.010560</td>\n",
              "      <td>-0.003460</td>\n",
              "      <td>-0.000526</td>\n",
              "      <td>-0.002241</td>\n",
              "      <td>-0.000108</td>\n",
              "      <td>0.010113</td>\n",
              "      <td>-0.002310</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.002055</td>\n",
              "      <td>-0.004472</td>\n",
              "      <td>-0.002529</td>\n",
              "      <td>0.003141</td>\n",
              "      <td>-0.006285</td>\n",
              "      <td>-0.003775</td>\n",
              "      <td>0.001709</td>\n",
              "      <td>-0.000619</td>\n",
              "      <td>-0.000750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Angina</th>\n",
              "      <td>0.003647</td>\n",
              "      <td>0.000502</td>\n",
              "      <td>0.007911</td>\n",
              "      <td>0.009775</td>\n",
              "      <td>-0.000882</td>\n",
              "      <td>0.000228</td>\n",
              "      <td>0.003273</td>\n",
              "      <td>0.002229</td>\n",
              "      <td>0.006129</td>\n",
              "      <td>-0.001348</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002055</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.003399</td>\n",
              "      <td>0.010733</td>\n",
              "      <td>-0.001165</td>\n",
              "      <td>-0.001482</td>\n",
              "      <td>0.000699</td>\n",
              "      <td>-0.007631</td>\n",
              "      <td>0.004531</td>\n",
              "      <td>-0.002611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Heart_Disease_History</th>\n",
              "      <td>0.004696</td>\n",
              "      <td>0.000630</td>\n",
              "      <td>-0.005312</td>\n",
              "      <td>0.006524</td>\n",
              "      <td>-0.000067</td>\n",
              "      <td>0.001396</td>\n",
              "      <td>0.010129</td>\n",
              "      <td>-0.001870</td>\n",
              "      <td>0.001747</td>\n",
              "      <td>0.002449</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.004472</td>\n",
              "      <td>-0.003399</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.001147</td>\n",
              "      <td>0.001604</td>\n",
              "      <td>-0.001613</td>\n",
              "      <td>-0.006655</td>\n",
              "      <td>-0.005640</td>\n",
              "      <td>0.004353</td>\n",
              "      <td>0.005415</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Diet</th>\n",
              "      <td>0.004960</td>\n",
              "      <td>0.002848</td>\n",
              "      <td>-0.000111</td>\n",
              "      <td>0.003050</td>\n",
              "      <td>0.004305</td>\n",
              "      <td>-0.001738</td>\n",
              "      <td>0.002635</td>\n",
              "      <td>0.000345</td>\n",
              "      <td>-0.005153</td>\n",
              "      <td>0.002364</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.002529</td>\n",
              "      <td>0.010733</td>\n",
              "      <td>-0.001147</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.000579</td>\n",
              "      <td>-0.008846</td>\n",
              "      <td>0.000972</td>\n",
              "      <td>0.001579</td>\n",
              "      <td>-0.003826</td>\n",
              "      <td>-0.000374</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sleep_Hours</th>\n",
              "      <td>-0.009355</td>\n",
              "      <td>-0.006928</td>\n",
              "      <td>-0.003595</td>\n",
              "      <td>-0.001150</td>\n",
              "      <td>-0.008843</td>\n",
              "      <td>0.003105</td>\n",
              "      <td>0.007489</td>\n",
              "      <td>0.002983</td>\n",
              "      <td>0.002280</td>\n",
              "      <td>-0.004560</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003141</td>\n",
              "      <td>-0.001165</td>\n",
              "      <td>0.001604</td>\n",
              "      <td>-0.000579</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.001683</td>\n",
              "      <td>-0.006784</td>\n",
              "      <td>-0.001963</td>\n",
              "      <td>-0.001707</td>\n",
              "      <td>-0.000031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Medication</th>\n",
              "      <td>-0.004225</td>\n",
              "      <td>-0.010958</td>\n",
              "      <td>0.003607</td>\n",
              "      <td>-0.006725</td>\n",
              "      <td>0.006578</td>\n",
              "      <td>-0.007269</td>\n",
              "      <td>-0.008292</td>\n",
              "      <td>0.005603</td>\n",
              "      <td>0.000927</td>\n",
              "      <td>-0.002703</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.006285</td>\n",
              "      <td>-0.001482</td>\n",
              "      <td>-0.001613</td>\n",
              "      <td>-0.008846</td>\n",
              "      <td>-0.001683</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.007815</td>\n",
              "      <td>0.000954</td>\n",
              "      <td>-0.001177</td>\n",
              "      <td>0.000193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Health_Awareness</th>\n",
              "      <td>0.006636</td>\n",
              "      <td>-0.004616</td>\n",
              "      <td>0.000250</td>\n",
              "      <td>-0.003992</td>\n",
              "      <td>0.001360</td>\n",
              "      <td>-0.003134</td>\n",
              "      <td>-0.001228</td>\n",
              "      <td>-0.002390</td>\n",
              "      <td>0.004412</td>\n",
              "      <td>0.001574</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.003775</td>\n",
              "      <td>0.000699</td>\n",
              "      <td>-0.006655</td>\n",
              "      <td>0.000972</td>\n",
              "      <td>-0.006784</td>\n",
              "      <td>0.007815</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.004641</td>\n",
              "      <td>-0.000371</td>\n",
              "      <td>0.007906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Daily_Water_Intake</th>\n",
              "      <td>0.001802</td>\n",
              "      <td>0.004287</td>\n",
              "      <td>-0.000070</td>\n",
              "      <td>-0.001918</td>\n",
              "      <td>-0.000098</td>\n",
              "      <td>-0.001232</td>\n",
              "      <td>-0.000040</td>\n",
              "      <td>-0.000949</td>\n",
              "      <td>-0.004509</td>\n",
              "      <td>-0.006140</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001709</td>\n",
              "      <td>-0.007631</td>\n",
              "      <td>-0.005640</td>\n",
              "      <td>0.001579</td>\n",
              "      <td>-0.001963</td>\n",
              "      <td>0.000954</td>\n",
              "      <td>-0.004641</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.001514</td>\n",
              "      <td>-0.000446</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mental_Health</th>\n",
              "      <td>-0.000388</td>\n",
              "      <td>0.002471</td>\n",
              "      <td>0.000600</td>\n",
              "      <td>0.003967</td>\n",
              "      <td>0.001024</td>\n",
              "      <td>0.000980</td>\n",
              "      <td>-0.001706</td>\n",
              "      <td>-0.001284</td>\n",
              "      <td>0.003781</td>\n",
              "      <td>-0.000389</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.000619</td>\n",
              "      <td>0.004531</td>\n",
              "      <td>0.004353</td>\n",
              "      <td>-0.003826</td>\n",
              "      <td>-0.001707</td>\n",
              "      <td>-0.001177</td>\n",
              "      <td>-0.000371</td>\n",
              "      <td>0.001514</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.000349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Obesity</th>\n",
              "      <td>0.004632</td>\n",
              "      <td>0.001732</td>\n",
              "      <td>-0.001415</td>\n",
              "      <td>0.006876</td>\n",
              "      <td>0.004433</td>\n",
              "      <td>-0.009421</td>\n",
              "      <td>0.004157</td>\n",
              "      <td>0.001542</td>\n",
              "      <td>-0.001294</td>\n",
              "      <td>0.009861</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.000750</td>\n",
              "      <td>-0.002611</td>\n",
              "      <td>0.005415</td>\n",
              "      <td>-0.000374</td>\n",
              "      <td>-0.000031</td>\n",
              "      <td>0.000193</td>\n",
              "      <td>0.007906</td>\n",
              "      <td>-0.000446</td>\n",
              "      <td>-0.000349</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>23 rows Ã— 23 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5e623729-3a37-4478-b28e-eda17ddddb1f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5e623729-3a37-4478-b28e-eda17ddddb1f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5e623729-3a37-4478-b28e-eda17ddddb1f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2d50214f-a273-4ff7-9961-4804f9829a85\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2d50214f-a273-4ff7-9961-4804f9829a85')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2d50214f-a273-4ff7-9961-4804f9829a85 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_1a3b4872-78ca-4d76-b0ee-28c2be123257\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('correlation_matrix')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_1a3b4872-78ca-4d76-b0ee-28c2be123257 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('correlation_matrix');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "correlation_matrix"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "# Identify categorical columns (excluding the target 'Heart_Attack')\n",
        "categorical_columns = df_new.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "label_encoders = {}\n",
        "for col in categorical_columns:\n",
        "    le = LabelEncoder()\n",
        "    df_new[col] = le.fit_transform(df_new[col])\n",
        "    label_encoders[col] = le\n",
        "\n",
        "# Correlation matrix\n",
        "correlation_matrix = df_new.corr()\n",
        "correlation_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "isx32_faZgdj"
      },
      "outputs": [],
      "source": [
        "# Define features and target variable\n",
        "X = df_new.drop(columns=['Heart_Attack'])  # Adjust column name as per dataset\n",
        "y = df_new['Heart_Attack']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YILEe2ftZrFO",
        "outputId": "0b925afe-8cd7-43b2-ff0e-e2f71a982df1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping catboost as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: numpy 2.0.2\n",
            "Uninstalling numpy-2.0.2:\n",
            "  Successfully uninstalled numpy-2.0.2\n",
            "Found existing installation: pandas 2.2.2\n",
            "Uninstalling pandas-2.2.2:\n",
            "  Successfully uninstalled pandas-2.2.2\n",
            "Collecting catboost\n",
            "  Downloading catboost-1.2.7-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting numpy==1.23.5\n",
            "  Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Collecting pandas==2.2.2\n",
            "  Downloading pandas-2.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Collecting python-dateutil>=2.8.2 (from pandas==2.2.2)\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting pytz>=2020.1 (from pandas==2.2.2)\n",
            "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas==2.2.2)\n",
            "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting graphviz (from catboost)\n",
            "  Downloading graphviz-0.20.3-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting matplotlib (from catboost)\n",
            "  Downloading matplotlib-3.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting scipy (from catboost)\n",
            "  Downloading scipy-1.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting plotly (from catboost)\n",
            "  Downloading plotly-6.0.1-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting six (from catboost)\n",
            "  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib->catboost)\n",
            "  Downloading contourpy-1.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib->catboost)\n",
            "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib->catboost)\n",
            "  Downloading fonttools-4.56.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (101 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m101.9/101.9 kB\u001b[0m \u001b[31m278.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib->catboost)\n",
            "  Downloading kiwisolver-1.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
            "Collecting packaging>=20.0 (from matplotlib->catboost)\n",
            "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting pillow>=8 (from matplotlib->catboost)\n",
            "  Downloading pillow-11.1.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
            "Collecting pyparsing>=2.3.1 (from matplotlib->catboost)\n",
            "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting narwhals>=1.15.1 (from plotly->catboost)\n",
            "  Downloading narwhals-1.32.0-py3-none-any.whl.metadata (9.2 kB)\n",
            "Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m301.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m288.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading catboost-1.2.7-cp311-cp311-manylinux2014_x86_64.whl (98.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m132.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m212.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m509.2/509.2 kB\u001b[0m \u001b[31m311.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m347.8/347.8 kB\u001b[0m \u001b[31m352.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphviz-0.20.3-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m47.1/47.1 kB\u001b[0m \u001b[31m274.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading matplotlib-3.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m264.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading plotly-6.0.1-py3-none-any.whl (14.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m14.8/14.8 MB\u001b[0m \u001b[31m218.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m37.6/37.6 MB\u001b[0m \u001b[31m264.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading contourpy-1.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (326 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m326.2/326.2 kB\u001b[0m \u001b[31m277.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Downloading fonttools-4.56.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m272.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kiwisolver-1.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m312.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading narwhals-1.32.0-py3-none-any.whl (320 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m320.1/320.1 kB\u001b[0m \u001b[31m167.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-24.2-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m300.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-11.1.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m269.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m111.1/111.1 kB\u001b[0m \u001b[31m227.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytz, tzdata, six, pyparsing, pillow, packaging, numpy, narwhals, kiwisolver, graphviz, fonttools, cycler, scipy, python-dateutil, plotly, contourpy, pandas, matplotlib, catboost\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2025.1\n",
            "    Uninstalling pytz-2025.1:\n",
            "      Successfully uninstalled pytz-2025.1\n",
            "  Attempting uninstall: tzdata\n",
            "    Found existing installation: tzdata 2025.1\n",
            "    Uninstalling tzdata-2025.1:\n",
            "      Successfully uninstalled tzdata-2025.1\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.17.0\n",
            "    Uninstalling six-1.17.0:\n",
            "      Successfully uninstalled six-1.17.0\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.2.1\n",
            "    Uninstalling pyparsing-3.2.1:\n",
            "      Successfully uninstalled pyparsing-3.2.1\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 11.1.0\n",
            "    Uninstalling pillow-11.1.0:\n",
            "      Successfully uninstalled pillow-11.1.0\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.2\n",
            "    Uninstalling packaging-24.2:\n",
            "      Successfully uninstalled packaging-24.2\n",
            "  Attempting uninstall: narwhals\n",
            "    Found existing installation: narwhals 1.31.0\n",
            "    Uninstalling narwhals-1.31.0:\n",
            "      Successfully uninstalled narwhals-1.31.0\n",
            "  Attempting uninstall: kiwisolver\n",
            "    Found existing installation: kiwisolver 1.4.8\n",
            "    Uninstalling kiwisolver-1.4.8:\n",
            "      Successfully uninstalled kiwisolver-1.4.8\n",
            "  Attempting uninstall: graphviz\n",
            "    Found existing installation: graphviz 0.20.3\n",
            "    Uninstalling graphviz-0.20.3:\n",
            "      Successfully uninstalled graphviz-0.20.3\n",
            "  Attempting uninstall: fonttools\n",
            "    Found existing installation: fonttools 4.56.0\n",
            "    Uninstalling fonttools-4.56.0:\n",
            "      Successfully uninstalled fonttools-4.56.0\n",
            "  Attempting uninstall: cycler\n",
            "    Found existing installation: cycler 0.12.1\n",
            "    Uninstalling cycler-0.12.1:\n",
            "      Successfully uninstalled cycler-0.12.1\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.14.1\n",
            "    Uninstalling scipy-1.14.1:\n",
            "      Successfully uninstalled scipy-1.14.1\n",
            "  Attempting uninstall: python-dateutil\n",
            "    Found existing installation: python-dateutil 2.8.2\n",
            "    Uninstalling python-dateutil-2.8.2:\n",
            "      Successfully uninstalled python-dateutil-2.8.2\n",
            "  Attempting uninstall: plotly\n",
            "    Found existing installation: plotly 5.24.1\n",
            "    Uninstalling plotly-5.24.1:\n",
            "      Successfully uninstalled plotly-5.24.1\n",
            "  Attempting uninstall: contourpy\n",
            "    Found existing installation: contourpy 1.3.1\n",
            "    Uninstalling contourpy-1.3.1:\n",
            "      Successfully uninstalled contourpy-1.3.1\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.10.0\n",
            "    Uninstalling matplotlib-3.10.0:\n",
            "      Successfully uninstalled matplotlib-3.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "chex 0.1.89 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "pymc 5.21.1 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.23.5 which is incompatible.\n",
            "xarray 2025.1.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "blosc2 3.2.0 requires numpy>=1.26, but you have numpy 1.23.5 which is incompatible.\n",
            "albucore 0.0.23 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "jax 0.5.2 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.23.5 which is incompatible.\n",
            "jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires numpy<3,>=1.24.3, but you have numpy 1.23.5 which is incompatible.\n",
            "scikit-image 0.25.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "bigframes 1.41.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "albumentations 2.0.5 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed catboost-1.2.7 contourpy-1.3.1 cycler-0.12.1 fonttools-4.56.0 graphviz-0.20.3 kiwisolver-1.4.8 matplotlib-3.10.1 narwhals-1.32.0 numpy-1.23.5 packaging-24.2 pandas-2.2.2 pillow-11.1.0 plotly-6.0.1 pyparsing-3.2.3 python-dateutil-2.9.0.post0 pytz-2025.2 scipy-1.15.2 six-1.17.0 tzdata-2025.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "cycler",
                  "dateutil",
                  "kiwisolver",
                  "numpy",
                  "six"
                ]
              },
              "id": "4b8ca4697a5d40e9a544b27897d8a5a6"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#!pip uninstall -y catboost numpy pandas\n",
        "#!pip install catboost numpy==1.23.5 pandas==2.2.2 --no-cache-dir --force-reinstall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QMCtaoaTZlIJ"
      },
      "outputs": [],
      "source": [
        "from catboost import CatBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, BaggingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DxEHot7HeST2"
      },
      "outputs": [],
      "source": [
        "def print_metrics(model_name, y_true, y_pred):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, average='weighted')\n",
        "    recall = recall_score(y_true, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "    print(f\"{model_name} - Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-YHyL4uZx8-",
        "outputId": "44e951b2-de9d-4382-d118-2c564d5ba8f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\tlearn: 0.6792988\ttotal: 145ms\tremaining: 2m 25s\n",
            "100:\tlearn: 0.4288413\ttotal: 4.72s\tremaining: 42s\n",
            "200:\tlearn: 0.3598683\ttotal: 8.61s\tremaining: 34.2s\n",
            "300:\tlearn: 0.3031956\ttotal: 14.5s\tremaining: 33.6s\n",
            "400:\tlearn: 0.2741480\ttotal: 19s\tremaining: 28.4s\n",
            "500:\tlearn: 0.2585820\ttotal: 23.6s\tremaining: 23.5s\n",
            "600:\tlearn: 0.2436001\ttotal: 29.4s\tremaining: 19.5s\n",
            "700:\tlearn: 0.2334252\ttotal: 34.4s\tremaining: 14.7s\n",
            "800:\tlearn: 0.2239576\ttotal: 36.4s\tremaining: 9.04s\n",
            "900:\tlearn: 0.2168291\ttotal: 39.5s\tremaining: 4.34s\n",
            "999:\tlearn: 0.2094958\ttotal: 41.1s\tremaining: 0us\n",
            "CatBoost Accuracy: 0.8747\n",
            "CatBoost - Accuracy: 0.8747, Precision: 0.7961, Recall: 0.8747, F1 Score: 0.8278\n",
            "Gaussian Naive Bayes Accuracy: 0.6088\n",
            "Gaussian Naive Bayes - Accuracy: 0.6088, Precision: 0.7961, Recall: 0.6088, F1 Score: 0.6778\n",
            "Random Forest Accuracy: 0.8394\n",
            "Random Forest - Accuracy: 0.8394, Precision: 0.7961, Recall: 0.8394, F1 Score: 0.8158\n",
            "Balanced Random Forest Accuracy: 0.8465\n",
            "Balanced Random Forest - Accuracy: 0.8465, Precision: 0.7898, Recall: 0.8465, F1 Score: 0.8157\n",
            "Decision Tree Accuracy: 0.4018\n",
            "Decision Tree - Accuracy: 0.4018, Precision: 0.7959, Recall: 0.4018, F1 Score: 0.4857\n",
            "KNN Accuracy: 0.5851\n",
            "KNN - Accuracy: 0.5851, Precision: 0.7947, Recall: 0.5851, F1 Score: 0.6594\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression Accuracy: 0.5257\n",
            "Logistic Regression - Accuracy: 0.5257, Precision: 0.7968, Recall: 0.5257, F1 Score: 0.6098\n",
            "Neural Network Accuracy: 0.6802\n",
            "Neural Network - Accuracy: 0.6802, Precision: 0.7960, Recall: 0.6802, F1 Score: 0.7284\n",
            "AdaBoost Accuracy: 0.6535\n",
            "AdaBoost - Accuracy: 0.6535, Precision: 0.7951, Recall: 0.6535, F1 Score: 0.7101\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [14:36:35] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XGBoost Accuracy: 0.8358\n",
            "XGBoost - Accuracy: 0.8358, Precision: 0.7934, Recall: 0.8358, F1 Score: 0.8130\n",
            "Gradient Boosting Accuracy: 0.7203\n",
            "Gradient Boosting - Accuracy: 0.7203, Precision: 0.7949, Recall: 0.7203, F1 Score: 0.7535\n",
            "Bagging Accuracy: 0.8061\n",
            "Bagging - Accuracy: 0.8061, Precision: 0.7971, Recall: 0.8061, F1 Score: 0.8015\n",
            "Neural Network Accuracy: 0.7433\n",
            "Neural Network - Accuracy: 0.7433, Precision: 0.7953, Recall: 0.7433, F1 Score: 0.7672\n"
          ]
        }
      ],
      "source": [
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(X, y, test_size=0.30, random_state=42)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train1)\n",
        "X_test = scaler.transform(X_test1)\n",
        "\n",
        "# Import necessary libraries\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from imblearn.ensemble import BalancedRandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "import numpy as np\n",
        "\n",
        "# Apply SMOTE for oversampling\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train1, y_train1)\n",
        "\n",
        "# Compute class weights\n",
        "classes = np.unique(y_train1)\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train1)\n",
        "class_weight_dict = dict(zip(classes, class_weights))\n",
        "\n",
        "# CatBoost\n",
        "cat_model1 = CatBoostClassifier(iterations=1000, learning_rate=0.05, depth=6, verbose=100, random_seed=42)\n",
        "cat_model1.fit(X_train_resampled, y_train_resampled)\n",
        "y_pred_cat1 = cat_model1.predict(X_test1)\n",
        "print(f\"CatBoost Accuracy: {accuracy_score(y_test1, y_pred_cat1):.4f}\")\n",
        "print_metrics(\"CatBoost\", y_test1, y_pred_cat1)\n",
        "\n",
        "# Gaussian Naive Bayes (No class_weight support)\n",
        "gaus_model1 = GaussianNB()\n",
        "gaus_model1.fit(X_train_resampled, y_train_resampled)\n",
        "y_pred_gaus1 = gaus_model1.predict(X_test1)\n",
        "print(f\"Gaussian Naive Bayes Accuracy: {accuracy_score(y_test1, y_pred_gaus1):.4f}\")\n",
        "print_metrics(\"Gaussian Naive Bayes\", y_test1, y_pred_gaus1)\n",
        "\n",
        "# Random Forest with class weights\n",
        "rf_model1 = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=0, class_weight='balanced')\n",
        "rf_model1.fit(X_train1, y_train1)\n",
        "y_pred_rf1 = rf_model1.predict(X_test1)\n",
        "print(f\"Random Forest Accuracy: {accuracy_score(y_test1, y_pred_rf1):.4f}\")\n",
        "print_metrics(\"Random Forest\", y_test1, y_pred_rf1)\n",
        "\n",
        "# Balanced Random Forest\n",
        "brf_model = BalancedRandomForestClassifier(n_estimators=100, random_state=42)\n",
        "brf_model.fit(X_train1, y_train1)\n",
        "y_pred_brf = brf_model.predict(X_test1)\n",
        "print(f\"Balanced Random Forest Accuracy: {accuracy_score(y_test1, y_pred_brf):.4f}\")\n",
        "print_metrics(\"Balanced Random Forest\", y_test1, y_pred_brf)\n",
        "\n",
        "# Decision Tree with class weights\n",
        "dt_model1 = DecisionTreeClassifier(max_depth=5, random_state=42, class_weight='balanced')\n",
        "dt_model1.fit(X_train1, y_train1)\n",
        "y_pred_dt1 = dt_model1.predict(X_test1)\n",
        "print(f\"Decision Tree Accuracy: {accuracy_score(y_test1, y_pred_dt1):.4f}\")\n",
        "print_metrics(\"Decision Tree\", y_test1, y_pred_dt1)\n",
        "\n",
        "# K Nearest Neighbors (SMOTE applied)\n",
        "knn_model1 = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_model1.fit(X_train_resampled, y_train_resampled)\n",
        "y_pred_knn1 = knn_model1.predict(X_test1)\n",
        "print(f\"KNN Accuracy: {accuracy_score(y_test1, y_pred_knn1):.4f}\")\n",
        "print_metrics(\"KNN\", y_test1, y_pred_knn1)\n",
        "\n",
        "# Logistic Regression with class weights\n",
        "lr_model1 = LogisticRegression(class_weight='balanced')\n",
        "lr_model1.fit(X_train1, y_train1)\n",
        "y_pred_lr1 = lr_model1.predict(X_test1)\n",
        "print(f\"Logistic Regression Accuracy: {accuracy_score(y_test1, y_pred_lr1):.4f}\")\n",
        "print_metrics(\"Logistic Regression\", y_test1, y_pred_lr1)\n",
        "\n",
        "# Neural Network with SMOTE\n",
        "nn_model = MLPClassifier(\n",
        "    hidden_layer_sizes=(74, 103),\n",
        "    activation='relu',\n",
        "    solver='sgd',\n",
        "    alpha=0.0020634128414587934,\n",
        "    learning_rate_init=0.001374130105225485,\n",
        "    max_iter=1000,\n",
        "    random_state=42\n",
        ")\n",
        "nn_model.fit(X_train_resampled, y_train_resampled)\n",
        "y_pred_nn = nn_model.predict(X_test1)\n",
        "print(f\"Neural Network Accuracy: {accuracy_score(y_test1, y_pred_nn):.4f}\")\n",
        "print_metrics(\"Neural Network\", y_test1, y_pred_nn)\n",
        "\n",
        "\n",
        "# AdaBoost (SMOTE applied)\n",
        "ada_model1 = AdaBoostClassifier(n_estimators=50)\n",
        "ada_model1.fit(X_train_resampled, y_train_resampled)\n",
        "y_pred_ada1 = ada_model1.predict(X_test1)\n",
        "print(f\"AdaBoost Accuracy: {accuracy_score(y_test1, y_pred_ada1):.4f}\")\n",
        "print_metrics(\"AdaBoost\", y_test1, y_pred_ada1)\n",
        "\n",
        "# XGBoost with scale_pos_weight\n",
        "xg_model1 = XGBClassifier(use_label_encoder=False, eval_metric='logloss', scale_pos_weight=class_weight_dict[1])\n",
        "xg_model1.fit(X_train1, y_train1)\n",
        "y_pred_xg1 = xg_model1.predict(X_test1)\n",
        "print(f\"XGBoost Accuracy: {accuracy_score(y_test1, y_pred_xg1):.4f}\")\n",
        "print_metrics(\"XGBoost\", y_test1, y_pred_xg1)\n",
        "\n",
        "# Gradient Boosting (SMOTE applied)\n",
        "gb_model1 = GradientBoostingClassifier(n_estimators=50)\n",
        "gb_model1.fit(X_train_resampled, y_train_resampled)\n",
        "y_pred_gb1 = gb_model1.predict(X_test1)\n",
        "print(f\"Gradient Boosting Accuracy: {accuracy_score(y_test1, y_pred_gb1):.4f}\")\n",
        "print_metrics(\"Gradient Boosting\", y_test1, y_pred_gb1)\n",
        "\n",
        "# Bagging (SMOTE applied)\n",
        "bag_model1 = BaggingClassifier(n_estimators=50)\n",
        "bag_model1.fit(X_train_resampled, y_train_resampled)\n",
        "y_pred_bag1 = bag_model1.predict(X_test1)\n",
        "print(f\"Bagging Accuracy: {accuracy_score(y_test1, y_pred_bag1):.4f}\")\n",
        "print_metrics(\"Bagging\", y_test1, y_pred_bag1)\n",
        "\n",
        "# Another Neural Network (SMOTE applied)\n",
        "nn_model1 = MLPClassifier(hidden_layer_sizes=(100, 50), activation='relu', max_iter=500)\n",
        "nn_model1.fit(X_train_resampled, y_train_resampled)\n",
        "y_pred_nn1 = nn_model1.predict(X_test1)\n",
        "print(f\"Neural Network Accuracy: {accuracy_score(y_test1, y_pred_nn1):.4f}\")\n",
        "print_metrics(\"Neural Network\", y_test1, y_pred_nn1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "fx-NO-2cl3Jc",
        "outputId": "2ff2e1f9-954b-45e7-cc15-cdf7c560d36e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\tlearn: 0.6519520\ttotal: 80.5ms\tremaining: 1m 20s\n",
            "100:\tlearn: 0.2396288\ttotal: 5.8s\tremaining: 51.6s\n",
            "200:\tlearn: 0.2204122\ttotal: 10.6s\tremaining: 42.1s\n",
            "300:\tlearn: 0.2084741\ttotal: 17.1s\tremaining: 39.6s\n",
            "400:\tlearn: 0.2016335\ttotal: 22s\tremaining: 32.9s\n",
            "500:\tlearn: 0.1959739\ttotal: 27.8s\tremaining: 27.7s\n",
            "600:\tlearn: 0.1908175\ttotal: 32.7s\tremaining: 21.7s\n",
            "700:\tlearn: 0.1862110\ttotal: 34.8s\tremaining: 14.8s\n",
            "800:\tlearn: 0.1817220\ttotal: 38.3s\tremaining: 9.52s\n",
            "900:\tlearn: 0.1772380\ttotal: 40.4s\tremaining: 4.44s\n",
            "999:\tlearn: 0.1729748\ttotal: 42.5s\tremaining: 0us\n",
            "CatBoost Accuracy: 0.8841\n",
            "CatBoost - Accuracy: 0.8841, Precision: 0.7818, Recall: 0.8841, F1 Score: 0.8298\n",
            "Gaussian Naive Bayes Accuracy: 0.5623\n",
            "Gaussian Naive Bayes - Accuracy: 0.5623, Precision: 0.7961, Recall: 0.5623, F1 Score: 0.6411\n",
            "Random Forest Accuracy: 0.8589\n",
            "Random Forest - Accuracy: 0.8589, Precision: 0.7950, Recall: 0.8589, F1 Score: 0.8227\n",
            "Balanced Random Forest Accuracy: 0.8787\n",
            "Balanced Random Forest - Accuracy: 0.8787, Precision: 0.7958, Recall: 0.8787, F1 Score: 0.8287\n",
            "Decision Tree Accuracy: 0.4018\n",
            "Decision Tree - Accuracy: 0.4018, Precision: 0.7959, Recall: 0.4018, F1 Score: 0.4857\n",
            "KNN Accuracy: 0.5687\n",
            "KNN - Accuracy: 0.5687, Precision: 0.7960, Recall: 0.5687, F1 Score: 0.6464\n",
            "Logistic Regression Accuracy: 0.5076\n",
            "Logistic Regression - Accuracy: 0.5076, Precision: 0.7971, Recall: 0.5076, F1 Score: 0.5934\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Neural Network Accuracy: 0.7689\n",
            "Neural Network - Accuracy: 0.7689, Precision: 0.7960, Recall: 0.7689, F1 Score: 0.7818\n",
            "SVM Accuracy: 0.5840\n",
            "SVM - Accuracy: 0.5840, Precision: 0.7961, Recall: 0.5840, F1 Score: 0.6586\n",
            "AdaBoost Accuracy: 0.8842\n",
            "AdaBoost - Accuracy: 0.8842, Precision: 0.7818, Recall: 0.8842, F1 Score: 0.8299\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XGBoost Accuracy: 0.8358\n",
            "XGBoost - Accuracy: 0.8358, Precision: 0.7934, Recall: 0.8358, F1 Score: 0.8130\n",
            "Gradient Boosting Accuracy: 0.8835\n",
            "Gradient Boosting - Accuracy: 0.8835, Precision: 0.7914, Recall: 0.8835, F1 Score: 0.8297\n",
            "Bagging Accuracy: 0.8839\n",
            "Bagging - Accuracy: 0.8839, Precision: 0.7818, Recall: 0.8839, F1 Score: 0.8297\n",
            "Neural Network Accuracy: 0.7486\n",
            "Neural Network - Accuracy: 0.7486, Precision: 0.7966, Recall: 0.7486, F1 Score: 0.7708\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import accuracy_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.ensemble import BalancedRandomForestClassifier\n",
        "\n",
        "# Models\n",
        "from catboost import CatBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Splitting dataset\n",
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(X, y, test_size=0.30, random_state=42)\n",
        "\n",
        "# Standardization\n",
        "scaler = StandardScaler()\n",
        "X_train1 = scaler.fit_transform(X_train1)\n",
        "X_test1 = scaler.transform(X_test1)\n",
        "\n",
        "# Apply SMOTE for oversampling\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train1, y_train1)\n",
        "\n",
        "# Compute class weights\n",
        "classes = np.unique(y_train1)\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train1)\n",
        "class_weight_dict = dict(zip(classes, class_weights))\n",
        "\n",
        "### **Model Training and Evaluation**\n",
        "# CatBoost (Handles imbalance natively)\n",
        "cat_model = CatBoostClassifier(iterations=1000, learning_rate=0.05, depth=6, verbose=100, random_seed=42)\n",
        "cat_model.fit(X_train_resampled, y_train_resampled)\n",
        "y_pred_cat = cat_model.predict(X_test1)\n",
        "print(f\"CatBoost Accuracy: {accuracy_score(y_test1, y_pred_cat):.4f}\")\n",
        "print_metrics(\"CatBoost\", y_test1, y_pred_cat)\n",
        "\n",
        "# Gaussian Naive Bayes\n",
        "gaus_model = GaussianNB()\n",
        "gaus_model.fit(X_train_resampled, y_train_resampled)\n",
        "y_pred_gaus = gaus_model.predict(X_test1)\n",
        "print(f\"Gaussian Naive Bayes Accuracy: {accuracy_score(y_test1, y_pred_gaus):.4f}\")\n",
        "print_metrics(\"Gaussian Naive Bayes\", y_test1, y_pred_gaus)\n",
        "\n",
        "# Random Forest with class weights\n",
        "rf_model = RandomForestClassifier(n_estimators=1000, max_depth=10, random_state=0, class_weight='balanced')\n",
        "rf_model.fit(X_train1, y_train1)\n",
        "y_pred_rf = rf_model.predict(X_test1)\n",
        "print(f\"Random Forest Accuracy: {accuracy_score(y_test1, y_pred_rf):.4f}\")\n",
        "print_metrics(\"Random Forest\", y_test1, y_pred_rf)\n",
        "\n",
        "# Balanced Random Forest\n",
        "brf_model = BalancedRandomForestClassifier(n_estimators=1000, random_state=42)\n",
        "brf_model.fit(X_train1, y_train1)\n",
        "y_pred_brf = brf_model.predict(X_test1)\n",
        "print(f\"Balanced Random Forest Accuracy: {accuracy_score(y_test1, y_pred_brf):.4f}\")\n",
        "print_metrics(\"Balanced Random Forest\", y_test1, y_pred_brf)\n",
        "\n",
        "# Decision Tree with class weights\n",
        "dt_model = DecisionTreeClassifier(max_depth=5, random_state=42, class_weight='balanced')\n",
        "dt_model.fit(X_train1, y_train1)\n",
        "y_pred_dt = dt_model.predict(X_test1)\n",
        "print(f\"Decision Tree Accuracy: {accuracy_score(y_test1, y_pred_dt):.4f}\")\n",
        "print_metrics(\"Decision Tree\", y_test1, y_pred_dt)\n",
        "\n",
        "# KNN (SMOTE applied)\n",
        "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_model.fit(X_train_resampled, y_train_resampled)\n",
        "y_pred_knn = knn_model.predict(X_test1)\n",
        "print(f\"KNN Accuracy: {accuracy_score(y_test1, y_pred_knn):.4f}\")\n",
        "print_metrics(\"KNN\", y_test1, y_pred_knn)\n",
        "\n",
        "# Logistic Regression with class weights\n",
        "lr_model = LogisticRegression(class_weight='balanced', max_iter=1000)\n",
        "lr_model.fit(X_train1, y_train1)\n",
        "y_pred_lr = lr_model.predict(X_test1)\n",
        "print(f\"Logistic Regression Accuracy: {accuracy_score(y_test1, y_pred_lr):.4f}\")\n",
        "print_metrics(\"Logistic Regression\", y_test1, y_pred_lr)\n",
        "\n",
        "# Neural Network (SMOTE applied)\n",
        "nn_model = MLPClassifier(\n",
        "    hidden_layer_sizes=(74, 103),\n",
        "    activation='relu',\n",
        "    solver='sgd',\n",
        "    alpha=0.0020634128414587934,\n",
        "    learning_rate_init=0.001374130105225485,\n",
        "    max_iter=1000,\n",
        "    random_state=42\n",
        ")\n",
        "nn_model.fit(X_train_resampled, y_train_resampled)\n",
        "y_pred_nn = nn_model.predict(X_test1)\n",
        "print(f\"Neural Network Accuracy: {accuracy_score(y_test1, y_pred_nn):.4f}\")\n",
        "print_metrics(\"Neural Network\", y_test1, y_pred_nn)\n",
        "\n",
        "# SVM with class weights\n",
        "svm_model = SVC(class_weight='balanced')\n",
        "svm_model.fit(X_train1, y_train1)\n",
        "y_pred_svm = svm_model.predict(X_test1)\n",
        "print(f\"SVM Accuracy: {accuracy_score(y_test1, y_pred_svm):.4f}\")\n",
        "print_metrics(\"SVM\", y_test1, y_pred_svm)\n",
        "\n",
        "# AdaBoost (SMOTE applied)\n",
        "ada_model = AdaBoostClassifier(n_estimators=1000)\n",
        "ada_model.fit(X_train_resampled, y_train_resampled)\n",
        "y_pred_ada = ada_model.predict(X_test1)\n",
        "print(f\"AdaBoost Accuracy: {accuracy_score(y_test1, y_pred_ada):.4f}\")\n",
        "print_metrics(\"AdaBoost\", y_test1, y_pred_ada)\n",
        "\n",
        "# XGBoost with scale_pos_weight\n",
        "scale_pos_weight = class_weight_dict.get(1, 1)  # Handle missing class 1 dynamically\n",
        "xg_model = XGBClassifier(eval_metric='logloss', scale_pos_weight=scale_pos_weight, random_state=42)\n",
        "xg_model.fit(X_train1, y_train1)\n",
        "y_pred_xg = xg_model.predict(X_test1)\n",
        "print(f\"XGBoost Accuracy: {accuracy_score(y_test1, y_pred_xg):.4f}\")\n",
        "print_metrics(\"XGBoost\", y_test1, y_pred_xg)\n",
        "\n",
        "# Gradient Boosting (SMOTE applied)\n",
        "gb_model = GradientBoostingClassifier(n_estimators=1000)\n",
        "gb_model.fit(X_train_resampled, y_train_resampled)\n",
        "y_pred_gb = gb_model.predict(X_test1)\n",
        "print(f\"Gradient Boosting Accuracy: {accuracy_score(y_test1, y_pred_gb):.4f}\")\n",
        "print_metrics(\"Gradient Boosting\", y_test1, y_pred_gb)\n",
        "\n",
        "# Bagging (SMOTE applied)\n",
        "bag_model = BaggingClassifier(n_estimators=1000)\n",
        "bag_model.fit(X_train_resampled, y_train_resampled)\n",
        "y_pred_bag = bag_model.predict(X_test1)\n",
        "print(f\"Bagging Accuracy: {accuracy_score(y_test1, y_pred_bag):.4f}\")\n",
        "print_metrics(\"Bagging\", y_test1, y_pred_bag)\n",
        "\n",
        "# Another Neural Network (SMOTE applied)\n",
        "nn_model1 = MLPClassifier(hidden_layer_sizes=(100, 50), activation='relu', max_iter=500, random_state=42)\n",
        "nn_model1.fit(X_train_resampled, y_train_resampled)\n",
        "y_pred_nn1 = nn_model1.predict(X_test1)\n",
        "print(f\"Neural Network Accuracy: {accuracy_score(y_test1, y_pred_nn1):.4f}\")\n",
        "print_metrics(\"Neural Network\", y_test1, y_pred_nn1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ic_JVbKk6bC",
        "outputId": "03ac401b-e089-4113-8739-36cd15bc22bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gaussian Naive Bayes Accuracy: 0.8824\n",
            "Decision Tree Optimized Accuracy: 0.7929\n",
            "KNN Optimized Accuracy: 0.6586\n",
            "Logistic Regression Optimized Accuracy: 0.6851\n",
            "Gaussian Naive Bayes - Accuracy: 0.8824, Precision: 0.7786, Recall: 0.8824, F1 Score: 0.8273\n",
            "Decision Tree Optimized - Accuracy: 0.7929, Precision: 0.7925, Recall: 0.7929, F1 Score: 0.7927\n",
            "KNN Optimized - Accuracy: 0.6586, Precision: 0.7949, Recall: 0.6586, F1 Score: 0.7131\n",
            "Logistic Regression Optimized - Accuracy: 0.6851, Precision: 0.7937, Recall: 0.6851, F1 Score: 0.7307\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import accuracy_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Models\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Load and split dataset (Replace with actual dataset)\n",
        "#df = pd.read_csv(\"/content/heart_attack_russia_youth_vs_adult (1).csv\")\n",
        "# Define features and target variable\n",
        "X = df_new.drop(columns=['Heart_Attack'])  # Adjust column name as per dataset\n",
        "y = df_new['Heart_Attack']\n",
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(X, y, test_size=0.30, random_state=42, stratify=y)\n",
        "\n",
        "# Apply SMOTE for KNN, Logistic Regression, and SVM (since they donâ€™t support class_weight)\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train1, y_train1)\n",
        "\n",
        "# Compute class weights (for Decision Tree and Logistic Regression)\n",
        "classes = np.unique(y_train1)\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train1)\n",
        "class_weight_dict = dict(zip(classes, class_weights))\n",
        "\n",
        "# Standardize features for KNN, Logistic Regression, and SVM\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train1)\n",
        "X_test_scaled = scaler.transform(X_test1)\n",
        "\n",
        "X_train_resampled_scaled = scaler.fit_transform(X_train_resampled)\n",
        "X_test_scaled_resampled = scaler.transform(X_test1)\n",
        "\n",
        "# ------------------ Gaussian Naive Bayes ------------------ #\n",
        "gnb_model = GaussianNB()\n",
        "gnb_model.fit(X_train1, y_train1)\n",
        "y_pred_gnb = gnb_model.predict(X_test1)\n",
        "print(f\"Gaussian Naive Bayes Accuracy: {accuracy_score(y_test1, y_pred_gnb):.4f}\")\n",
        "\n",
        "# ------------------ Decision Tree (Tuned) ------------------ #\n",
        "param_grid_dt = {\n",
        "    'max_depth': [5, 10, 15, None],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 5],\n",
        "    'criterion': ['gini', 'entropy']\n",
        "}\n",
        "dt_grid = GridSearchCV(DecisionTreeClassifier(random_state=42, class_weight=class_weight_dict),\n",
        "                       param_grid_dt, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "dt_grid.fit(X_train1, y_train1)\n",
        "\n",
        "best_dt_model = dt_grid.best_estimator_\n",
        "y_pred_dt = best_dt_model.predict(X_test1)\n",
        "print(f\"Decision Tree Optimized Accuracy: {accuracy_score(y_test1, y_pred_dt):.4f}\")\n",
        "\n",
        "# ------------------ K-Nearest Neighbors (Tuned) ------------------ #\n",
        "param_grid_knn = {'n_neighbors': [3, 5, 7, 9, 11]}\n",
        "knn_grid = GridSearchCV(KNeighborsClassifier(), param_grid_knn, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "knn_grid.fit(X_train_resampled_scaled, y_train_resampled)\n",
        "\n",
        "best_knn_model = knn_grid.best_estimator_\n",
        "y_pred_knn = best_knn_model.predict(X_test_scaled_resampled)\n",
        "print(f\"KNN Optimized Accuracy: {accuracy_score(y_test1, y_pred_knn):.4f}\")\n",
        "\n",
        "# ------------------ Logistic Regression (Tuned) ------------------ #\n",
        "param_grid_lr = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],  # Regularization strength\n",
        "    'solver': ['liblinear', 'lbfgs']\n",
        "}\n",
        "lr_grid = GridSearchCV(LogisticRegression(class_weight='balanced', max_iter=1000),\n",
        "                       param_grid_lr, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "lr_grid.fit(X_train_resampled_scaled, y_train_resampled)\n",
        "\n",
        "best_lr_model = lr_grid.best_estimator_\n",
        "y_pred_lr = best_lr_model.predict(X_test_scaled_resampled)\n",
        "print(f\"Logistic Regression Optimized Accuracy: {accuracy_score(y_test1, y_pred_lr):.4f}\")\n",
        "\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Function to print evaluation metrics\n",
        "def print_metrics(model_name, y_true, y_pred):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, average='weighted')\n",
        "    recall = recall_score(y_true, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "    print(f\"{model_name} - Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
        "\n",
        "# Gaussian Naive Bayes\n",
        "print_metrics(\"Gaussian Naive Bayes\", y_test1, y_pred_gnb)\n",
        "\n",
        "# Decision Tree (Tuned)\n",
        "print_metrics(\"Decision Tree Optimized\", y_test1, y_pred_dt)\n",
        "\n",
        "# K-Nearest Neighbors (Tuned)\n",
        "print_metrics(\"KNN Optimized\", y_test1, y_pred_knn)\n",
        "\n",
        "# Logistic Regression (Tuned)\n",
        "print_metrics(\"Logistic Regression Optimized\", y_test1, y_pred_lr)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpMWkc62foTC",
        "outputId": "daabf2e5-f68f-47d0-f195-9674fe26e588"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\tlearn: 0.6518863\ttotal: 69ms\tremaining: 34.4s\n",
            "100:\tlearn: 0.2387984\ttotal: 2.02s\tremaining: 7.97s\n",
            "200:\tlearn: 0.2216464\ttotal: 3.96s\tremaining: 5.89s\n",
            "300:\tlearn: 0.2102924\ttotal: 6s\tremaining: 3.96s\n",
            "400:\tlearn: 0.2038898\ttotal: 8.92s\tremaining: 2.2s\n",
            "499:\tlearn: 0.1986948\ttotal: 10.7s\tremaining: 0us\n",
            "0:\tlearn: 0.6518863\ttotal: 23.3ms\tremaining: 11.6s\n",
            "100:\tlearn: 0.2387984\ttotal: 1.98s\tremaining: 7.82s\n",
            "200:\tlearn: 0.2216464\ttotal: 3.93s\tremaining: 5.84s\n",
            "300:\tlearn: 0.2102924\ttotal: 5.94s\tremaining: 3.93s\n",
            "400:\tlearn: 0.2038898\ttotal: 7.86s\tremaining: 1.94s\n",
            "499:\tlearn: 0.1986948\ttotal: 9.83s\tremaining: 0us\n",
            "Voting Classifier Accuracy: 0.8864\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import accuracy_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.ensemble import BalancedRandomForestClassifier\n",
        "\n",
        "# Models\n",
        "from catboost import CatBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "# Splitting dataset\n",
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "\n",
        "# Standardization\n",
        "scaler = StandardScaler()\n",
        "X_train1 = scaler.fit_transform(X_train1)\n",
        "X_test1 = scaler.transform(X_test1)\n",
        "\n",
        "# Apply SMOTE for oversampling\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train1, y_train1)\n",
        "\n",
        "# Compute class weights\n",
        "classes = np.unique(y_train1)\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train1)\n",
        "class_weight_dict = dict(zip(classes, class_weights))\n",
        "\n",
        "### **Model Training**\n",
        "# Gaussian Naive Bayes\n",
        "gaus_model = GaussianNB()\n",
        "gaus_model.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Balanced Random Forest\n",
        "brf_model = BalancedRandomForestClassifier(n_estimators=500, random_state=42)\n",
        "brf_model.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Decision Tree\n",
        "dt_model = DecisionTreeClassifier(max_depth=5, random_state=42, class_weight='balanced')\n",
        "dt_model.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# AdaBoost\n",
        "ada_model = AdaBoostClassifier(n_estimators=500, random_state=42)\n",
        "ada_model.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Gradient Boosting\n",
        "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
        "gb_model.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# XGBoost\n",
        "xg_model = XGBClassifier(eval_metric='logloss', random_state=42)\n",
        "xg_model.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# CatBoost\n",
        "cat_model = CatBoostClassifier(iterations=500, learning_rate=0.05, depth=6, verbose=100, random_seed=42)\n",
        "cat_model.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Bagging\n",
        "bag_model = BaggingClassifier(n_estimators=500, random_state=42)\n",
        "bag_model.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "### **Voting Classifier (Majority Vote)**\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('gnb', gaus_model),\n",
        "        ('brf', brf_model),\n",
        "        ('dt', dt_model),\n",
        "        ('adaboost', ada_model),\n",
        "        ('grad_boost', gb_model),\n",
        "        ('xgb', xg_model),\n",
        "        ('catboost', cat_model),\n",
        "        ('bagging', bag_model)\n",
        "    ],\n",
        "    voting='hard'  # Hard voting selects the majority class\n",
        ")\n",
        "\n",
        "# Train the voting classifier\n",
        "voting_clf.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Predict using the voting classifier\n",
        "y_pred_voting = voting_clf.predict(X_test1)\n",
        "\n",
        "# Print accuracy and performance metrics\n",
        "def print_metrics(model_name, y_true, y_pred):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    print(f\"{model_name} Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "print_metrics(\"Voting Classifier\", y_test1, y_pred_voting)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ho6wbmoxwIt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45681588-e070-471b-9065-3aa8ac1fb42d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Voting Classifier - Accuracy: 0.8864, Precision: 0.7857, Recall: 0.8864, F1 Score: 0.8330\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "def print_metrics1(model_name, y_true, y_pred):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, average='weighted')\n",
        "    recall = recall_score(y_true, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "    print(f\"{model_name} - Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
        "print_metrics1(\"Voting Classifier\", y_test1, y_pred_voting)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZOmbkEdw4QJ"
      },
      "outputs": [],
      "source": [
        "categorical_columns = df_new.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "label_encoders = {}\n",
        "for col in categorical_columns:\n",
        "    le = LabelEncoder()\n",
        "    df_new[col] = le.fit_transform(df_new[col])\n",
        "    label_encoders[col] = le\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "px2LtZ7Rr10Z",
        "outputId": "1a729762-795e-462a-a0c8-421a7e3c0983"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "could not convert string to float: 'Female'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-5fd18357e2bf>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Ensure the test sample is standardized using the same scaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtest_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Predict using the trained voting classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m   1060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m         \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1062\u001b[0;31m         X = validate_data(\n\u001b[0m\u001b[1;32m   1063\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1064\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2942\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2944\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2945\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2946\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1053\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1055\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1056\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1057\u001b[0m                 raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[1;32m    837\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 839\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m         \u001b[0;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Female'"
          ]
        }
      ],
      "source": [
        "# Define a test sample (Replace with actual feature values)\n",
        "test_sample = np.array([[32,'Female','Rural',104.3,257.4,17.6,60,'Low','TRUE','None','TRUE','FALSE',10]])  # Example input\n",
        "\n",
        "# Ensure the test sample is standardized using the same scaler\n",
        "test_sample = scaler.transform(test_sample)\n",
        "\n",
        "# Predict using the trained voting classifier\n",
        "predicted_label = voting_clf.predict(test_sample)\n",
        "\n",
        "# Interpret the result\n",
        "result = \"Prone to Heart Attack\" if predicted_label[0] == 1 else \"Not Prone to Heart Attack\"\n",
        "print(f\"Test Sample Prediction: {result}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8IAZgCTIxf8Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5caed3c3-5c8a-4749-a90b-813b42fb3286"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial null value counts:\n",
            " Age                          0\n",
            "Gender                       0\n",
            "Region                       0\n",
            "Blood_Pressure               0\n",
            "Cholesterol                  0\n",
            "BMI                          0\n",
            "Heart_Rate                   0\n",
            "Exercise_Level               0\n",
            "Smoking                      0\n",
            "Alcohol_Consumption      25024\n",
            "Diabetes                     0\n",
            "Family_History               0\n",
            "Stress_Level                 0\n",
            "Heart_Attack                 0\n",
            "Angina                       0\n",
            "Heart_Disease_History        0\n",
            "Diet                         0\n",
            "Sleep_Hours                  0\n",
            "Medication                   0\n",
            "Health_Awareness             0\n",
            "Daily_Water_Intake           0\n",
            "Mental_Health                0\n",
            "Obesity                      0\n",
            "dtype: int64\n",
            "\n",
            "Final null value counts:\n",
            " Age                      0\n",
            "Gender                   0\n",
            "Region                   0\n",
            "Blood_Pressure           0\n",
            "Cholesterol              0\n",
            "BMI                      0\n",
            "Heart_Rate               0\n",
            "Exercise_Level           0\n",
            "Smoking                  0\n",
            "Alcohol_Consumption      0\n",
            "Diabetes                 0\n",
            "Family_History           0\n",
            "Stress_Level             0\n",
            "Heart_Attack             0\n",
            "Angina                   0\n",
            "Heart_Disease_History    0\n",
            "Diet                     0\n",
            "Sleep_Hours              0\n",
            "Medication               0\n",
            "Health_Awareness         0\n",
            "Daily_Water_Intake       0\n",
            "Mental_Health            0\n",
            "Obesity                  0\n",
            "dtype: int64\n",
            "\n",
            "Final DataFrame shape: (50000, 23)\n",
            "Error in conversion to float: could not convert string to float: 'FALSE'\n",
            "Problematic data: [[0 0 0 0 0 0 0 0 0 0 0 0 0 'FALSE' 'FALSE' 'Healthy' 9.9 'TRUE' 1 1.3 7\n",
            "  'FALSE']]\n",
            "Still unable to convert column 13 with value: FALSE\n",
            "Still unable to convert column 14 with value: FALSE\n",
            "Still unable to convert column 15 with value: Healthy\n",
            "Still unable to convert column 17 with value: TRUE\n",
            "Still unable to convert column 21 with value: FALSE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Sample Prediction: Not Prone to Heart Attack\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Ensure all float columns have valid values\n",
        "df_new = df.copy()\n",
        "print(\"Initial null value counts:\\n\", df_new.isnull().sum())\n",
        "\n",
        "# Handle negative and missing values in float columns\n",
        "for col in df_new.select_dtypes(include=['float']).columns:\n",
        "    positive_values = df_new[col][df_new[col] > 0]\n",
        "    if not positive_values.empty:\n",
        "        mean_value = positive_values.mean()\n",
        "        df_new[col] = df_new[col].apply(lambda x: mean_value if x <= 0 or pd.isnull(x) else x)\n",
        "\n",
        "# Convert non-numeric columns to string\n",
        "for column in df_new.select_dtypes(exclude='number').columns:\n",
        "    df_new[column] = df_new[column].astype(str)\n",
        "\n",
        "# Drop unnecessary columns\n",
        "df_new = df_new.loc[:, ~df_new.columns.str.contains('^Unnamed')]\n",
        "df_new = df_new.dropna()\n",
        "\n",
        "print(\"\\nFinal null value counts:\\n\", df_new.isnull().sum())\n",
        "print(\"\\nFinal DataFrame shape:\", df_new.shape)\n",
        "\n",
        "# ----------------- TEST SAMPLE PROCESSING ----------------- #\n",
        "\n",
        "# Define a test sample (Replace with actual feature values)\n",
        "test_sample = np.array([['32', 'Female', 'Rural', 104.3, 257.4, 17.6, 60, 'Low', 'TRUE', 'None', 'TRUE', 'FALSE', 10,\n",
        "                         'FALSE', 'FALSE', 'Healthy', 9.9, 'TRUE', 1, 1.3, 7, 'FALSE']], dtype=object)\n",
        "\n",
        "# Convert categorical values using the saved label encoders\n",
        "for i, col in enumerate(categorical_columns):\n",
        "    if col in label_encoders:  # Check if the column was encoded in training\n",
        "        try:\n",
        "            # Encode known values\n",
        "            test_sample[0, i] = label_encoders[col].transform([test_sample[0, i]])[0]\n",
        "        except ValueError:\n",
        "            # Handle unseen values: replace with the most frequent category\n",
        "            most_common_category = label_encoders[col].classes_[0]  # Get first category from trained encoder\n",
        "            test_sample[0, i] = label_encoders[col].transform([most_common_category])[0]\n",
        "\n",
        "# Convert all string values to float properly\n",
        "try:\n",
        "    test_sample = np.array(test_sample, dtype=float)\n",
        "except ValueError as e:\n",
        "    print(f\"Error in conversion to float: {e}\")\n",
        "    print(f\"Problematic data: {test_sample}\")\n",
        "\n",
        "    # Try a second approach by iterating and converting elements one by one\n",
        "    for i in range(test_sample.shape[1]):\n",
        "        try:\n",
        "            test_sample[0, i] = float(test_sample[0, i])\n",
        "        except ValueError:\n",
        "            print(f\"Still unable to convert column {i} with value: {test_sample[0, i]}\")\n",
        "            test_sample[0, i] = 0.0  # Replace non-convertible values with 0.0\n",
        "\n",
        "# Ensure the test sample is standardized using the same scaler\n",
        "test_sample_scaled = scaler.transform(test_sample.reshape(1, -1))  # Reshape for transformation\n",
        "\n",
        "# Predict using the trained voting classifier\n",
        "predicted_label = voting_clf.predict(test_sample_scaled)\n",
        "\n",
        "# Interpret the result\n",
        "result = \"Prone to Heart Attack\" if predicted_label[0] == 1 else \"Not Prone to Heart Attack\"\n",
        "print(f\"Test Sample Prediction: {result}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "voting code with better prediction"
      ],
      "metadata": {
        "id": "pz-X0uKSyqyz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import VotingClassifier, RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, BaggingClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier, Pool\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "\n",
        "# Fix for CatBoost inside VotingClassifier\n",
        "class SklearnCompatibleCatBoost(CatBoostClassifier):\n",
        "    def fit(self, X, y):\n",
        "        return super().fit(Pool(X, label=y), verbose=0)\n",
        "\n",
        "# Define models with best parameters\n",
        "models = [\n",
        "    ('gnb', GaussianNB()),  # Gaussian NaÃ¯ve Bayes\n",
        "    ('rf', RandomForestClassifier(n_estimators=500, random_state=42)),  # Balanced Random Forest\n",
        "    ('dt', DecisionTreeClassifier(random_state=42)),  # Decision Tree\n",
        "    ('ada', AdaBoostClassifier(n_estimators=500, random_state=42)),  # AdaBoost\n",
        "    ('gb', GradientBoostingClassifier(n_estimators=100, random_state=42)),  # Gradient Boosting (Updated)\n",
        "    ('xgb', XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)),  # XGBoost\n",
        "    ('cat', SklearnCompatibleCatBoost(iterations=500, random_state=42)),  # Fixed CatBoost\n",
        "    ('bag', BaggingClassifier(n_estimators=500, random_state=42))  # Bagging (Updated)\n",
        "]\n",
        "\n",
        "# Create a Voting Classifier (Soft Voting for probabilistic averaging)\n",
        "voting_clf = VotingClassifier(estimators=models, voting='soft')\n",
        "\n",
        "# Train the ensemble model\n",
        "voting_clf.fit(X_train_resampled_scaled, y_train_resampled)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = voting_clf.predict(X_test_scaled_resampled)\n",
        "\n",
        "# Evaluate performance\n",
        "print(\"Accuracy:\", accuracy_score(y_test1, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test1, y_pred))\n",
        "\n",
        "print_metrics(\"Logistic Regression Optimized\", y_test1, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iy_rgwWIt0h-",
        "outputId": "371daee7-6744-47d1-eed2-0a99a56fc94a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [09:47:23] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7996\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.89      0.89     13236\n",
            "           1       0.13      0.13      0.13      1764\n",
            "\n",
            "    accuracy                           0.80     15000\n",
            "   macro avg       0.51      0.51      0.51     15000\n",
            "weighted avg       0.80      0.80      0.80     15000\n",
            "\n",
            "Logistic Regression Optimized - Accuracy: 0.7996, Precision: 0.7960, Recall: 0.7996, F1 Score: 0.7978\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define the test sample (raw values)\n",
        "test_sample = {\n",
        "    \"Age\": 53,\n",
        "    \"Gender\": \"Female\",\n",
        "    \"Region\": \"Urban\",\n",
        "    \"Blood_Pressure\": 115.9,\n",
        "    \"Cholesterol\": 231.9,\n",
        "    \"BMI\": 32,\n",
        "    \"Heart_Rate\": 76,\n",
        "    \"Exercise_Level\": \"Moderate\",\n",
        "    \"Smoking\": \"False\",\n",
        "    \"Alcohol_Consumption\": \"Moderate\",\n",
        "    \"Diabetes\": \"False\",\n",
        "    \"Family_History\": \"False\",\n",
        "    \"Stress_Level\": 1,\n",
        "    \"Angina\": \"False\",\n",
        "    \"Heart_Disease_History\": \"False\",\n",
        "    \"Diet\": \"Mixed\",\n",
        "    \"Sleep_Hours\": 4.2,\n",
        "    \"Medication\": \"True\",\n",
        "    \"Health_Awareness\": 4,\n",
        "    \"Daily_Water_Intake\": 3.4,\n",
        "    \"Mental_Health\": 2,\n",
        "    \"Obesity\": \"False\"\n",
        "}\n",
        "\n",
        "# Encoding mappings from your dataset\n",
        "encoding_map = {\n",
        "    'Gender': {'Female': 0, 'Male': 1, 'Other': 2},\n",
        "    'Region': {'Rural': 0, 'Suburban': 1, 'Urban': 2},\n",
        "    'Exercise_Level': {'High': 0, 'Low': 1, 'Moderate': 2},\n",
        "    'Smoking': {'False': 0, 'True': 1},\n",
        "    'Alcohol_Consumption': {'Heavy': 0, 'Moderate': 1, 'None': 2},\n",
        "    'Diabetes': {'False': 0, 'True': 1},\n",
        "    'Family_History': {'False': 0, 'True': 1},\n",
        "    'Angina': {'False': 0, 'True': 1},\n",
        "    'Heart_Disease_History': {'False': 0, 'True': 1},\n",
        "    'Diet': {'Healthy': 0, 'Mixed': 1, 'Unhealthy': 2},\n",
        "    'Medication': {'False': 0, 'True': 1},\n",
        "    'Obesity': {'False': 0, 'True': 1}\n",
        "}\n",
        "\n",
        "# Apply encoding to categorical and boolean values\n",
        "encoded_sample = {}\n",
        "for feature, value in test_sample.items():\n",
        "    if feature in encoding_map:  # If categorical or boolean, encode it\n",
        "        encoded_sample[feature] = encoding_map[feature][value]\n",
        "    else:  # If numerical, keep as is\n",
        "        encoded_sample[feature] = value\n",
        "\n",
        "# Convert dictionary to NumPy array (reshape for model input)\n",
        "test_sample_array = np.array(list(encoded_sample.values())).reshape(1, -1)\n",
        "\n",
        "# Standardize test sample using the same scaler used in training\n",
        "test_sample_scaled = scaler.transform(test_sample_array)\n",
        "\n",
        "# Predict probability for the test sample\n",
        "test_pred_proba = voting_clf.predict_proba(test_sample_scaled)[0]  # Get probability for both classes\n",
        "\n",
        "# Display the probability of heart attack risk\n",
        "print(\"\\nðŸ” **Test Sample Prediction:**\")\n",
        "print(f\"Chance of NO Heart Attack: {test_pred_proba[0] * 100:.2f}%\")\n",
        "print(f\"Chance of Heart Attack: {test_pred_proba[1] * 100:.2f}%\")\n",
        "\n",
        "# Predict class label\n",
        "test_pred_label = voting_clf.predict(test_sample_scaled)[0]\n",
        "print(f\"\\nFinal Prediction: {'Heart Attack' if test_pred_label == 1 else 'No Heart Attack'}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nl1Ywiity8sj",
        "outputId": "11c641b2-9d9a-44d3-b652-6dd7a404c357"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ” **Test Sample Prediction:**\n",
            "Chance of NO Heart Attack: 52.34%\n",
            "Chance of Heart Attack: 47.66%\n",
            "\n",
            "Final Prediction: No Heart Attack\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}